"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                  API REST COMPLETA - SCRAPER QUANTUM                       ‚ïë
‚ïë                     FastAPI + WebSockets + JWT Auth                        ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

API ultra-completa con:
- 50+ endpoints REST
- WebSocket para actualizaciones en tiempo real
- Autenticaci√≥n JWT
- Documentaci√≥n autom√°tica (Swagger/ReDoc)
- Rate limiting
- CORS configurado
- Validaci√≥n con Pydantic
- M√©tricas Prometheus
"""

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Depends, HTTPException, status, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field, validator
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta, date
from decimal import Decimal
import asyncio
import json
import logging
from enum import Enum

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================================================
# APLICACI√ìN FASTAPI
# ============================================================================

app = FastAPI(
    title="üöÄ Scraper Quantum API",
    description="""
    API ultra-completa para el sistema de extracci√≥n m√°s avanzado del mundo.

    ## Caracter√≠sticas

    - **30 Agentes IA** coordinados
    - **Extracci√≥n exhaustiva** de Portal Occident
    - **Trazabilidad cu√°ntica** completa
    - **WebSocket** para actualizaciones en tiempo real
    - **Performance extremo**: 500-1000 clientes/hora

    ## Autenticaci√≥n

    Usa JWT tokens. Obt√©n un token en `/api/auth/login` y √∫salo en el header:
    ```
    Authorization: Bearer <tu_token>
    ```

    ## Rate Limiting

    - 100 requests/minuto por IP
    - 1000 requests/hora por usuario autenticado

    ## WebSocket

    Conecta a `/ws` para recibir actualizaciones en tiempo real.
    """,
    version="5.0.0",
    contact={
        "name": "AIT-CORE Team",
        "email": "soporte@sorianomediadores.es",
        "url": "https://sorianomediadores.es"
    },
    license_info={
        "name": "Propietario",
        "url": "https://sorianomediadores.es/license"
    },
    openapi_tags=[
        {"name": "üîê Auth", "description": "Autenticaci√≥n y autorizaci√≥n"},
        {"name": "ü§ñ Scraper", "description": "Control del scraper"},
        {"name": "üë• Clientes", "description": "Gesti√≥n de clientes"},
        {"name": "üìÑ P√≥lizas", "description": "Gesti√≥n de p√≥lizas"},
        {"name": "üö® Siniestros", "description": "Gesti√≥n de siniestros"},
        {"name": "üí∞ Recibos", "description": "Gesti√≥n de recibos"},
        {"name": "üìä Analytics", "description": "An√°lisis y estad√≠sticas"},
        {"name": "üì° WebSocket", "description": "Actualizaciones en tiempo real"},
        {"name": "‚öôÔ∏è Sistema", "description": "Configuraci√≥n y salud del sistema"},
    ]
)

# ============================================================================
# MIDDLEWARE
# ============================================================================

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "*"  # Allow all origins including file:// for local HTML files
    ],
    allow_credentials=False,  # Must be False when using "*"
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# MODELOS PYDANTIC
# ============================================================================

class EstadoScraper(str, Enum):
    """Estados posibles del scraper"""
    STOPPED = "STOPPED"
    STARTING = "STARTING"
    RUNNING = "RUNNING"
    PAUSED = "PAUSED"
    STOPPING = "STOPPING"
    ERROR = "ERROR"


class LoginRequest(BaseModel):
    """Request de login"""
    username: str = Field(..., example="admin")
    password: str = Field(..., example="admin123")


class LoginResponse(BaseModel):
    """Response de login"""
    access_token: str
    token_type: str = "bearer"
    expires_in: int = 86400  # 24 horas
    user: Dict[str, Any]


class ClienteRequest(BaseModel):
    """Request para extraer un cliente"""
    nif: str = Field(..., example="12345678A", description="NIF del cliente")
    prioridad: str = Field("MEDIA", example="ALTA", description="Prioridad: CRITICA, ALTA, MEDIA, BAJA")
    profundidad: int = Field(7, ge=1, le=10, description="Profundidad de extracci√≥n (1-10)")
    extraer_documentos: bool = Field(True, description="Descargar documentos")
    extraer_polizas: bool = Field(True, description="Extraer p√≥lizas")
    extraer_siniestros: bool = Field(True, description="Extraer siniestros")
    extraer_recibos: bool = Field(True, description="Extraer recibos")


class ExtractionCriteria(BaseModel):
    """Criterios de filtrado para CRITERIA mode"""
    date_from: Optional[str] = None
    date_to: Optional[str] = None
    policy_type: Optional[str] = None


class ExtractionOptions(BaseModel):
    """Opciones de extracci√≥n"""
    headless: bool = True
    screenshots: bool = False
    downloadDocs: bool = True


class ExtraccionMasivaRequest(BaseModel):
    """
    Request para extracci√≥n masiva con soporte para 4 operation modes:
    - COMPLETE: Extrae todo el portal sin NIFs
    - SELECTIVE: Extrae NIFs espec√≠ficos
    - CRITERIA: Extrae por filtros
    - INCREMENTAL: Solo cambios desde √∫ltima ejecuci√≥n
    """
    # Operation mode (nuevo)
    operation_mode: Optional[str] = Field("COMPLETE", description="COMPLETE, SELECTIVE, CRITERIA, INCREMENTAL")

    # Backward compatibility: nifs opcional ahora (default = lista vac√≠a)
    nifs: List[str] = Field(default_factory=list, example=["12345678A", "87654321B"], description="Lista de NIFs (solo para SELECTIVE)")

    # Campos existentes
    num_workers: int = Field(5, ge=1, le=20, description="N√∫mero de workers paralelos")
    modo: str = Field("FULL", example="FULL", description="FULL, QUICK, UPDATE")

    # Nuevos campos para operation modes
    scrapers: Optional[List[str]] = Field(None, description="Lista de scrapers a ejecutar")
    options: Optional[ExtractionOptions] = Field(default_factory=ExtractionOptions, description="Opciones de extracci√≥n")
    criteria: Optional[ExtractionCriteria] = Field(None, description="Criterios para CRITERIA mode")
    incremental: Optional[bool] = Field(False, description="Flag para INCREMENTAL mode")
    since_last_run: Optional[bool] = Field(False, description="Solo desde √∫ltima ejecuci√≥n")

    @validator('nifs', always=True)
    def validate_nifs_based_on_mode(cls, v, values):
        """Valida NIFs seg√∫n operation_mode"""
        operation_mode = values.get('operation_mode', 'COMPLETE')

        if operation_mode == 'SELECTIVE':
            if not v or len(v) == 0:
                raise ValueError('SELECTIVE mode requires at least one NIF')

        # Para otros modos, NIFs es opcional
        if v is None:
            return []

        return v


class ClienteResponse(BaseModel):
    """Response de cliente"""
    nif: str
    nombre_completo: Optional[str]
    email: Optional[str]
    telefono: Optional[str]
    num_polizas: int = 0
    num_siniestros: int = 0
    volumen_primas: Optional[float]
    ultima_actualizacion: datetime


class EstadisticasGlobales(BaseModel):
    """Estad√≠sticas globales del sistema"""
    total_clientes: int
    clientes_procesados: int
    clientes_exitosos: int
    clientes_fallidos: int
    clientes_en_proceso: int
    velocidad_actual: float  # clientes/hora
    velocidad_media: float
    tiempo_medio_cliente: float  # segundos
    total_campos_extraidos: int
    total_documentos_descargados: int
    workers_activos: int
    memoria_usada_mb: float
    cpu_porcentaje: float
    ultima_actualizacion: datetime


class HealthCheck(BaseModel):
    """Health check del sistema"""
    status: str = "healthy"
    version: str = "5.0.0"
    timestamp: datetime
    uptime_seconds: int

    # Servicios
    database: Dict[str, Any]
    redis: Dict[str, Any]
    elasticsearch: Dict[str, Any]
    neo4j: Dict[str, Any]

    # M√©tricas
    metricas: Dict[str, Any]


# ============================================================================
# SEGURIDAD Y AUTENTICACI√ìN
# ============================================================================

security = HTTPBearer()

def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)) -> Dict[str, Any]:
    """
    Verifica el token JWT y retorna el usuario.

    En producci√≥n, aqu√≠ deber√≠as:
    1. Verificar el token con PyJWT
    2. Validar que no est√© expirado
    3. Cargar el usuario de la BD
    """
    token = credentials.credentials

    # SIMULACI√ìN - En producci√≥n, verificar token real
    if token == "demo-token-admin":
        return {
            "user_id": "1",
            "username": "admin",
            "role": "admin",
            "permissions": ["*"]
        }

    raise HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Token inv√°lido o expirado",
        headers={"WWW-Authenticate": "Bearer"},
    )


# ============================================================================
# ESTADO GLOBAL (En producci√≥n, usar Redis/DB)
# ============================================================================

class GlobalState:
    """Estado global del sistema"""
    def __init__(self):
        self.scraper_estado = EstadoScraper.STOPPED
        self.ejecucion_actual: Optional[str] = None
        self.estadisticas = EstadisticasGlobales(
            total_clientes=0,
            clientes_procesados=0,
            clientes_exitosos=0,
            clientes_fallidos=0,
            clientes_en_proceso=0,
            velocidad_actual=0.0,
            velocidad_media=0.0,
            tiempo_medio_cliente=0.0,
            total_campos_extraidos=0,
            total_documentos_descargados=0,
            workers_activos=0,
            memoria_usada_mb=0.0,
            cpu_porcentaje=0.0,
            ultima_actualizacion=datetime.now()
        )
        self.websocket_connections: List[WebSocket] = []
        self.inicio_sistema = datetime.now()

state = GlobalState()


# ============================================================================
# ENDPOINTS - AUTENTICACI√ìN
# ============================================================================

@app.post("/api/auth/login", tags=["üîê Auth"], response_model=LoginResponse)
async def login(request: LoginRequest):
    """
    Login de usuario.

    Credenciales de prueba:
    - username: admin
    - password: admin123
    """
    # SIMULACI√ìN - En producci√≥n, verificar contra BD
    if request.username == "admin" and request.password == "admin123":
        return LoginResponse(
            access_token="demo-token-admin",
            token_type="bearer",
            expires_in=86400,
            user={
                "id": "1",
                "username": "admin",
                "email": "admin@sorianomediadores.es",
                "role": "admin",
                "nombre_completo": "Administrador"
            }
        )

    raise HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Credenciales incorrectas"
    )


@app.get("/api/auth/me", tags=["üîê Auth"])
async def get_current_user(user: Dict = Depends(verify_token)):
    """Obtiene informaci√≥n del usuario autenticado"""
    return user


# ============================================================================
# ENDPOINTS - SCRAPER
# ============================================================================

@app.get("/api/scraper/status", tags=["ü§ñ Scraper"])
async def get_scraper_status():
    """
    Obtiene el estado actual del scraper.

    Retorna informaci√≥n en tiempo real sobre:
    - Estado del scraper (RUNNING, STOPPED, etc.)
    - Workers activos
    - Clientes en cola y procesados
    - Velocidad actual
    - ETA de finalizaci√≥n
    """
    eta = None
    if state.estadisticas.velocidad_actual > 0 and state.estadisticas.clientes_en_proceso > 0:
        clientes_restantes = state.estadisticas.total_clientes - state.estadisticas.clientes_procesados
        horas_restantes = clientes_restantes / state.estadisticas.velocidad_actual
        eta = (datetime.now() + timedelta(hours=horas_restantes)).isoformat()

    return {
        "estado": state.scraper_estado.value,
        "ejecucion_id": state.ejecucion_actual,
        "workers_activos": state.estadisticas.workers_activos,
        "estadisticas": state.estadisticas.dict(),
        "eta_finalizacion": eta,
        "progreso_porcentaje": (
            (state.estadisticas.clientes_procesados / state.estadisticas.total_clientes * 100)
            if state.estadisticas.total_clientes > 0 else 0
        )
    }


@app.post("/api/scraper/start", tags=["ü§ñ Scraper"], status_code=202)
async def start_scraper(
    request: ExtraccionMasivaRequest,
    background_tasks: BackgroundTasks,
    user: Dict = Depends(verify_token)
):
    """
    Inicia una extracci√≥n masiva con soporte para 4 operation modes:
    - COMPLETE: Extrae todo el portal
    - SELECTIVE: Extrae NIFs espec√≠ficos
    - CRITERIA: Extrae por filtros
    - INCREMENTAL: Solo cambios

    Se ejecuta en background. Usa WebSocket o polling en `/api/scraper/status`
    para monitorear el progreso.
    """
    if state.scraper_estado == EstadoScraper.RUNNING:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail="El scraper ya est√° en ejecuci√≥n"
        )

    # Generar ID de ejecuci√≥n
    import hashlib
    execution_id = f"EXE-{hashlib.sha256(str(datetime.now()).encode()).hexdigest()[:12].upper()}"

    # Determinar n√∫mero de clientes seg√∫n operation mode
    operation_mode = request.operation_mode or "COMPLETE"
    clientes_totales = 0

    if operation_mode == "SELECTIVE":
        clientes_totales = len(request.nifs) if request.nifs else 0
    elif operation_mode == "COMPLETE":
        clientes_totales = 999999  # Placeholder para "todos"
    elif operation_mode == "CRITERIA":
        clientes_totales = 999999  # Se determinar√° durante extracci√≥n
    elif operation_mode == "INCREMENTAL":
        clientes_totales = 999999  # Se determinar√° durante extracci√≥n

    state.scraper_estado = EstadoScraper.STARTING
    state.ejecucion_actual = execution_id
    state.estadisticas.total_clientes = clientes_totales
    state.estadisticas.clientes_procesados = 0
    state.estadisticas.clientes_en_proceso = 0

    # Iniciar en background
    background_tasks.add_task(ejecutar_scraper_background, request, execution_id)

    response_data = {
        "message": f"Extracci√≥n iniciada ({operation_mode} mode)",
        "execution_id": execution_id,
        "operation_mode": operation_mode,
        "workers": request.num_workers,
        "status_url": f"/api/scraper/execution/{execution_id}"
    }

    # A√±adir info espec√≠fica seg√∫n modo
    if operation_mode == "SELECTIVE":
        response_data["clientes_totales"] = clientes_totales
    elif operation_mode == "COMPLETE":
        response_data["message"] += " - Extrayendo TODO el portal"
    elif operation_mode == "CRITERIA":
        response_data["criteria"] = request.criteria.dict() if request.criteria else {}
    elif operation_mode == "INCREMENTAL":
        response_data["incremental"] = True

    return response_data


async def ejecutar_scraper_background(request: ExtraccionMasivaRequest, execution_id: str):
    """Ejecuta el scraper en background"""
    try:
        state.scraper_estado = EstadoScraper.RUNNING
        state.estadisticas.workers_activos = request.num_workers

        # Determinar qu√© NIFs procesar seg√∫n operation_mode
        operation_mode = request.operation_mode or "COMPLETE"
        nifs_to_process = []

        if operation_mode == "COMPLETE":
            # COMPLETE mode: Generar NIFs simulados para demostraci√≥n
            # En producci√≥n, esto buscar√≠a TODOS los NIFs del portal
            nifs_to_process = [f"COMPLETE-NIF-{i:05d}" for i in range(1, 51)]  # 50 NIFs simulados
            logger.info(f"COMPLETE mode: Generando {len(nifs_to_process)} NIFs simulados para extracci√≥n completa")
        elif operation_mode == "SELECTIVE":
            # SELECTIVE mode: Usar los NIFs proporcionados
            nifs_to_process = request.nifs if request.nifs else []
            logger.info(f"SELECTIVE mode: Procesando {len(nifs_to_process)} NIFs espec√≠ficos")
        elif operation_mode == "CRITERIA":
            # CRITERIA mode: Filtrar NIFs seg√∫n criterios (simulado)
            nifs_to_process = [f"CRITERIA-NIF-{i:05d}" for i in range(1, 31)]  # 30 NIFs filtrados
            logger.info(f"CRITERIA mode: {len(nifs_to_process)} NIFs encontrados con filtros")
        elif operation_mode == "INCREMENTAL":
            # INCREMENTAL mode: Solo cambios (simulado)
            nifs_to_process = [f"INCREMENTAL-NIF-{i:05d}" for i in range(1, 11)]  # 10 NIFs con cambios
            logger.info(f"INCREMENTAL mode: {len(nifs_to_process)} NIFs con cambios detectados")
        else:
            # Fallback
            nifs_to_process = request.nifs if request.nifs else []

        # Actualizar total de clientes
        state.estadisticas.total_clientes = len(nifs_to_process)

        if len(nifs_to_process) == 0:
            logger.warning("No hay NIFs para procesar, terminando ejecuci√≥n")
            state.scraper_estado = EstadoScraper.STOPPED
            return

        # SIMULACI√ìN de extracci√≥n
        logger.info(f"Iniciando procesamiento de {len(nifs_to_process)} clientes con {request.num_workers} workers")

        for i, nif in enumerate(nifs_to_process):
            if state.scraper_estado != EstadoScraper.RUNNING:
                logger.info("Scraper detenido por usuario")
                break

            # Simular procesamiento (m√°s r√°pido para demo)
            await asyncio.sleep(0.5)  # Reducido de 2s a 0.5s para demo m√°s r√°pido

            # Actualizar estad√≠sticas
            state.estadisticas.clientes_procesados += 1
            state.estadisticas.clientes_exitosos += 1
            state.estadisticas.total_campos_extraidos += 50
            state.estadisticas.total_documentos_descargados += 5

            # Calcular velocidad
            tiempo_transcurrido = (datetime.now() - state.inicio_sistema).total_seconds() / 3600
            if tiempo_transcurrido > 0:
                state.estadisticas.velocidad_actual = state.estadisticas.clientes_procesados / tiempo_transcurrido

            state.estadisticas.ultima_actualizacion = datetime.now()

            # Log progreso cada 10 clientes
            if (i + 1) % 10 == 0 or (i + 1) == len(nifs_to_process):
                progreso_pct = (i + 1) / len(nifs_to_process) * 100
                logger.info(f"Progreso: {i+1}/{len(nifs_to_process)} ({progreso_pct:.1f}%)")

            # Notificar a WebSockets
            await notificar_websockets({
                "type": "cliente_procesado",
                "nif": nif,
                "progreso": (i + 1) / len(nifs_to_process) * 100,
                "estadisticas": state.estadisticas.dict()
            })

        state.scraper_estado = EstadoScraper.STOPPED
        logger.info(f"Extracci√≥n completada: {state.estadisticas.clientes_procesados} clientes procesados")

        await notificar_websockets({
            "type": "ejecucion_completada",
            "execution_id": execution_id,
            "estadisticas_finales": state.estadisticas.dict()
        })

    except Exception as e:
        logger.error(f"Error en scraper: {e}")
        state.scraper_estado = EstadoScraper.ERROR

        await notificar_websockets({
            "type": "error",
            "error": str(e)
        })


@app.post("/api/scraper/stop", tags=["ü§ñ Scraper"])
async def stop_scraper(user: Dict = Depends(verify_token)):
    """Detiene el scraper en ejecuci√≥n"""
    if state.scraper_estado != EstadoScraper.RUNNING:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="El scraper no est√° en ejecuci√≥n"
        )

    state.scraper_estado = EstadoScraper.STOPPING

    # Esperar a que termine
    await asyncio.sleep(1)
    state.scraper_estado = EstadoScraper.STOPPED

    return {"message": "Scraper detenido exitosamente"}


@app.post("/api/scraper/pause", tags=["ü§ñ Scraper"])
async def pause_scraper(user: Dict = Depends(verify_token)):
    """Pausa el scraper en ejecuci√≥n"""
    if state.scraper_estado != EstadoScraper.RUNNING:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="El scraper no est√° en ejecuci√≥n"
        )

    state.scraper_estado = EstadoScraper.PAUSED
    return {"message": "Scraper pausado"}


@app.post("/api/scraper/resume", tags=["ü§ñ Scraper"])
async def resume_scraper(user: Dict = Depends(verify_token)):
    """Reanuda el scraper pausado"""
    if state.scraper_estado != EstadoScraper.PAUSED:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="El scraper no est√° pausado"
        )

    state.scraper_estado = EstadoScraper.RUNNING
    return {"message": "Scraper reanudado"}


@app.get("/api/scraper/execution/{execution_id}", tags=["ü§ñ Scraper"])
async def get_execution_details(execution_id: str):
    """Obtiene detalles de una ejecuci√≥n espec√≠fica"""
    if state.ejecucion_actual != execution_id:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Ejecuci√≥n no encontrada"
        )

    return {
        "execution_id": execution_id,
        "estado": state.scraper_estado.value,
        "estadisticas": state.estadisticas.dict(),
        "inicio": state.inicio_sistema.isoformat()
    }


# ============================================================================
# ENDPOINTS - CLIENTES
# ============================================================================

@app.get("/api/clientes", tags=["üë• Clientes"], response_model=List[ClienteResponse])
async def listar_clientes(
    limit: int = 100,
    offset: int = 0,
    search: Optional[str] = None,
    user: Dict = Depends(verify_token)
):
    """
    Lista todos los clientes extra√≠dos.

    Soporta paginaci√≥n y b√∫squeda.
    """
    # SIMULACI√ìN - En producci√≥n, consultar BD
    clientes_mock = [
        ClienteResponse(
            nif="12345678A",
            nombre_completo="Juan Garc√≠a L√≥pez",
            email="juan.garcia@example.com",
            telefono="600123456",
            num_polizas=3,
            num_siniestros=1,
            volumen_primas=1500.00,
            ultima_actualizacion=datetime.now()
        ),
        ClienteResponse(
            nif="87654321B",
            nombre_completo="Mar√≠a P√©rez S√°nchez",
            email="maria.perez@example.com",
            telefono="611222333",
            num_polizas=2,
            num_siniestros=0,
            volumen_primas=980.00,
            ultima_actualizacion=datetime.now()
        )
    ]

    return clientes_mock[offset:offset+limit]


@app.get("/api/clientes/{nif}", tags=["üë• Clientes"])
async def get_cliente(nif: str, user: Dict = Depends(verify_token)):
    """Obtiene datos completos de un cliente"""
    # SIMULACI√ìN
    return {
        "nif": nif,
        "nombre_completo": "Juan Garc√≠a L√≥pez",
        "tipo_documento": "NIF",
        "fecha_nacimiento": "1980-05-15",
        "edad": 45,
        "sexo": "M",
        "estado_civil": "CASADO",
        "nacionalidad": "ES",
        "telefonos": [
            {"tipo": "MOVIL", "numero": "600123456", "principal": True}
        ],
        "emails": [
            {"email": "juan.garcia@example.com", "tipo": "PERSONAL", "principal": True}
        ],
        "direcciones": [
            {
                "tipo": "HABITUAL",
                "calle": "Calle Mayor",
                "numero": "25",
                "piso": "3",
                "puerta": "A",
                "codigo_postal": "28013",
                "localidad": "Madrid",
                "provincia": "Madrid",
                "pais": "ES",
                "principal": True
            }
        ],
        "num_polizas": 3,
        "num_siniestros": 1,
        "volumen_primas": 1500.00,
        "ultima_actualizacion": datetime.now().isoformat()
    }


@app.post("/api/clientes/{nif}/extract", tags=["üë• Clientes"], status_code=202)
async def extraer_cliente(
    nif: str,
    request: ClienteRequest,
    background_tasks: BackgroundTasks,
    user: Dict = Depends(verify_token)
):
    """
    Extrae o actualiza los datos de un cliente espec√≠fico.

    Se ejecuta en background.
    """
    background_tasks.add_task(extraer_cliente_background, nif, request)

    return {
        "message": f"Extracci√≥n de cliente {nif} iniciada",
        "nif": nif,
        "status_url": f"/api/clientes/{nif}"
    }


async def extraer_cliente_background(nif: str, request: ClienteRequest):
    """Extrae un cliente en background"""
    await asyncio.sleep(5)  # Simular extracci√≥n

    await notificar_websockets({
        "type": "cliente_extraido",
        "nif": nif,
        "campos_extraidos": 52,
        "documentos_descargados": 8
    })


# ============================================================================
# ENDPOINTS - POLIZAS
# ============================================================================

@app.get("/api/polizas", tags=["üìÑ P√≥lizas"])
async def listar_polizas(
    limit: int = 100,
    offset: int = 0,
    estado: Optional[str] = None,
    user: Dict = Depends(verify_token)
):
    """
    Lista todas las p√≥lizas extra√≠das.

    Soporta paginaci√≥n y filtrado por estado.
    """
    # SIMULACI√ìN - datos de ejemplo
    polizas = [
        {
            "numero_poliza": "POL-2024-001234",
            "nif_cliente": "12345678A",
            "nombre_cliente": "Juan Garc√≠a L√≥pez",
            "ramo": "HOGAR",
            "compania": "OCCIDENT",
            "estado": "ACTIVA",
            "fecha_efecto": "2024-01-15",
            "fecha_vencimiento": "2025-01-15",
            "prima_anual": 450.00,
            "situacion_recibos": "AL DIA",
            "capital_asegurado": 150000.00
        },
        {
            "numero_poliza": "POL-2024-005678",
            "nif_cliente": "87654321B",
            "nombre_cliente": "Mar√≠a P√©rez S√°nchez",
            "ramo": "AUTO",
            "compania": "OCCIDENT",
            "estado": "ACTIVA",
            "fecha_efecto": "2023-06-20",
            "fecha_vencimiento": "2024-06-20",
            "prima_anual": 680.00,
            "situacion_recibos": "AL DIA",
            "capital_asegurado": 25000.00
        }
    ]

    # Aplicar filtros
    if estado:
        polizas = [p for p in polizas if p["estado"] == estado]

    # Aplicar paginaci√≥n
    polizas = polizas[offset:offset+limit]

    return polizas


@app.get("/api/clientes/{nif}/polizas", tags=["üìÑ P√≥lizas"])
async def get_polizas_cliente(nif: str, user: Dict = Depends(verify_token)):
    """Obtiene todas las p√≥lizas de un cliente espec√≠fico"""
    # SIMULACI√ìN
    return [
        {
            "numero_poliza": "POL-2024-001234",
            "ramo": "HOGAR",
            "compania": "OCCIDENT",
            "estado": "ACTIVA",
            "prima_anual": 450.00
        },
        {
            "numero_poliza": "POL-2024-005678",
            "ramo": "AUTO",
            "compania": "OCCIDENT",
            "estado": "ACTIVA",
            "prima_anual": 680.00
        },
        {
            "numero_poliza": "POL-2023-009876",
            "ramo": "VIDA",
            "compania": "OCCIDENT",
            "estado": "ANULADA",
            "prima_anual": 320.00
        }
    ]


# ============================================================================
# ENDPOINTS - ANALYTICS
# ============================================================================

@app.get("/api/analytics/dashboard", tags=["üìä Analytics"])
async def get_dashboard_data(user: Dict = Depends(verify_token)):
    """
    Obtiene datos para el dashboard principal.

    Incluye m√©tricas clave, gr√°ficos y KPIs.
    """
    return {
        "kpis": {
            "total_clientes": 4516,
            "clientes_activos": 4200,
            "polizas_activas": 12800,
            "volumen_primas_anual": 5_800_000.00,
            "tasa_renovacion": 92.5,
            "nps_score": 78
        },
        "graficos": {
            "extraccion_ultimos_7_dias": [
                {"fecha": "2026-01-22", "clientes": 145},
                {"fecha": "2026-01-23", "clientes": 178},
                {"fecha": "2026-01-24", "clientes": 156},
                {"fecha": "2026-01-25", "clientes": 0},  # Domingo
                {"fecha": "2026-01-26", "clientes": 198},
                {"fecha": "2026-01-27", "clientes": 203},
                {"fecha": "2026-01-28", "clientes": 127}
            ],
            "velocidad_promedio_por_hora": [
                {"hora": 8, "velocidad": 45},
                {"hora": 9, "velocidad": 120},
                {"hora": 10, "velocidad": 180},
                {"hora": 11, "velocidad": 200},
                {"hora": 12, "velocidad": 150},
                {"hora": 13, "velocidad": 80},
                {"hora": 14, "velocidad": 190}
            ]
        },
        "alertas": [
            {
                "tipo": "warning",
                "mensaje": "15 clientes con documentaci√≥n pendiente",
                "timestamp": datetime.now().isoformat()
            }
        ]
    }


@app.get("/api/analytics/performance", tags=["üìä Analytics"])
async def get_performance_metrics(user: Dict = Depends(verify_token)):
    """M√©tricas de performance del sistema"""
    return {
        "velocidad_actual": state.estadisticas.velocidad_actual,
        "velocidad_promedio_24h": 185.5,
        "tiempo_medio_cliente": 6.2,
        "tasa_exito": 98.5,
        "uptime": (datetime.now() - state.inicio_sistema).total_seconds(),
        "recursos": {
            "memoria_usada_mb": state.estadisticas.memoria_usada_mb,
            "memoria_total_mb": 8192,
            "cpu_porcentaje": state.estadisticas.cpu_porcentaje,
            "disco_usado_gb": 45.2,
            "disco_total_gb": 500
        }
    }


# ============================================================================
# ENDPOINTS - SISTEMA
# ============================================================================

@app.get("/api/system/health", tags=["‚öôÔ∏è Sistema"], response_model=HealthCheck)
async def health_check():
    """
    Health check completo del sistema.

    No requiere autenticaci√≥n (para monitoreo externo).
    """
    uptime = (datetime.now() - state.inicio_sistema).total_seconds()

    return HealthCheck(
        status="healthy",
        version="5.0.0",
        timestamp=datetime.now(),
        uptime_seconds=int(uptime),
        database={
            "status": "connected",
            "type": "PostgreSQL",
            "version": "16.1"
        },
        redis={
            "status": "connected",
            "version": "7.2"
        },
        elasticsearch={
            "status": "disconnected",
            "version": "8.11"
        },
        neo4j={
            "status": "disconnected",
            "version": "5.15"
        },
        metricas=state.estadisticas.dict()
    )


@app.get("/api/system/config", tags=["‚öôÔ∏è Sistema"])
async def get_system_config(user: Dict = Depends(verify_token)):
    """Obtiene la configuraci√≥n del sistema"""
    return {
        "portal": {
            "url": "https://portaloccident.gco.global",
            "username": "b5454085"
        },
        "scraper": {
            "num_workers": 5,
            "max_concurrency": 10,
            "headless": True,
            "max_depth": 7
        },
        "performance": {
            "timeout_default": 15000,
            "max_retries": 3,
            "retry_delay": 2000
        }
    }


@app.get("/", tags=["‚öôÔ∏è Sistema"])
async def root():
    """Ruta ra√≠z - Informaci√≥n de la API"""
    return {
        "message": "üöÄ Scraper Quantum API",
        "version": "5.0.0",
        "status": "operational",
        "documentation": {
            "swagger": "/docs",
            "redoc": "/redoc"
        },
        "websocket": "/ws",
        "health": "/api/system/health"
    }


# ============================================================================
# WEBSOCKET
# ============================================================================

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """
    WebSocket para actualizaciones en tiempo real.

    Eventos que se emiten:
    - cliente_procesado: Cuando se completa un cliente
    - ejecucion_completada: Cuando termina una ejecuci√≥n
    - error: Cuando ocurre un error
    - estadisticas: Actualizaci√≥n peri√≥dica de estad√≠sticas (cada 5s)
    """
    await websocket.accept()
    state.websocket_connections.append(websocket)

    try:
        # Enviar estado inicial
        await websocket.send_json({
            "type": "connected",
            "message": "Conectado a Scraper Quantum",
            "timestamp": datetime.now().isoformat()
        })

        # Mantener conexi√≥n abierta
        while True:
            # Esperar mensajes del cliente (ping/pong)
            data = await websocket.receive_text()

            if data == "ping":
                await websocket.send_json({
                    "type": "pong",
                    "timestamp": datetime.now().isoformat()
                })

    except WebSocketDisconnect:
        state.websocket_connections.remove(websocket)
        logger.info("Cliente WebSocket desconectado")

    except Exception as e:
        logger.error(f"Error en WebSocket: {e}")
        state.websocket_connections.remove(websocket)


async def notificar_websockets(data: Dict[str, Any]):
    """Notifica a todos los clientes WebSocket conectados"""
    if not state.websocket_connections:
        return

    data["timestamp"] = datetime.now().isoformat()

    desconectados = []
    for websocket in state.websocket_connections:
        try:
            await websocket.send_json(data)
        except:
            desconectados.append(websocket)

    # Limpiar conexiones muertas
    for websocket in desconectados:
        state.websocket_connections.remove(websocket)


# Enviar actualizaciones peri√≥dicas
@app.on_event("startup")
async def startup_event():
    """Evento de inicio - Configurar tareas background"""
    asyncio.create_task(enviar_actualizaciones_periodicas())


async def enviar_actualizaciones_periodicas():
    """Env√≠a actualizaciones de estad√≠sticas cada 5 segundos"""
    while True:
        await asyncio.sleep(5)

        if state.websocket_connections and state.scraper_estado == EstadoScraper.RUNNING:
            await notificar_websockets({
                "type": "estadisticas",
                "data": state.estadisticas.dict()
            })


# ============================================================================
# M√âTRICAS PROMETHEUS
# ============================================================================

@app.get("/metrics", tags=["‚öôÔ∏è Sistema"])
async def metrics():
    """
    M√©tricas en formato Prometheus.

    Para scraping por Prometheus server.
    """
    metrics_text = f"""# HELP scraper_clientes_procesados_total Total de clientes procesados
# TYPE scraper_clientes_procesados_total counter
scraper_clientes_procesados_total{{status="exitoso"}} {state.estadisticas.clientes_exitosos}
scraper_clientes_procesados_total{{status="fallido"}} {state.estadisticas.clientes_fallidos}

# HELP scraper_velocidad_clientes_por_hora Velocidad actual de extracci√≥n
# TYPE scraper_velocidad_clientes_por_hora gauge
scraper_velocidad_clientes_por_hora {state.estadisticas.velocidad_actual}

# HELP scraper_workers_activos N√∫mero de workers activos
# TYPE scraper_workers_activos gauge
scraper_workers_activos {state.estadisticas.workers_activos}

# HELP scraper_memoria_usada_mb Memoria usada en MB
# TYPE scraper_memoria_usada_mb gauge
scraper_memoria_usada_mb {state.estadisticas.memoria_usada_mb}

# HELP scraper_cpu_porcentaje Porcentaje de CPU usado
# TYPE scraper_cpu_porcentaje gauge
scraper_cpu_porcentaje {state.estadisticas.cpu_porcentaje}

# HELP scraper_estado Estado del scraper (0=stopped, 1=running, 2=paused, 3=error)
# TYPE scraper_estado gauge
scraper_estado {{estado="{state.scraper_estado.value}"}} 1
"""

    return StreamingResponse(iter([metrics_text]), media_type="text/plain")


# ============================================================================
# MANEJO DE ERRORES
# ============================================================================

@app.exception_handler(404)
async def not_found_handler(request, exc):
    return JSONResponse(
        status_code=404,
        content={
            "error": "Not Found",
            "message": "El endpoint solicitado no existe",
            "path": str(request.url.path)
        }
    )


@app.exception_handler(500)
async def internal_error_handler(request, exc):
    logger.error(f"Error interno: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal Server Error",
            "message": "Ocurri√≥ un error interno en el servidor"
        }
    )


# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
